			+--------------------+
			|        CS 153      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Wolfgang Finkbeiner 	wfink001@ucr.edu	861128797
Andy Thio 		athio001@ucr.edu 	861098878

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	Thread.h struct thread was changed to include int_64t wait_ticks.
To wake waiting processes, threads must contain variable to remember when they will wake.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

	Timer sleep moves a thread to a wait que and assings thread with a date for waking.
When timer interrupt encounters a thread ready for execution, timer interrupt compares current ticks with the thread waking date, and moves any appropriate threads to the ready que.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

	Rather than looking through the list and comparing the wait date of each thread to the current ticks, timer_interrupt will only look at the first item in the que. If the wait date is still in the future, then the function will move on. If the wait date has passed, the thread will be popped from the que and timer_interrupt will have another check. 
---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

	Rather than waiting for a process to finish waiting, Interupts are only disabled to move them to a que. Moving threads to a que off of ready processes avoids needing to hold one process at a time. 

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

	Wait ticks isn't a shared resource, its unique to each thread. Therefore, timer interrupt, when checking wait time, doesn't interrupt all sleeping processes or processes being put under. 

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	Our current design has many advantages to busy waiting, as we have allready mentioned. Waiting now allows other processes to execute while a thread is on hold. This not only means that a thread can exectute sooner, but other threads looking to wait can now wait in parallelism with other threads, greatly reducing the time of execution for waiting threads. 

	One big disadvantage to our implementation (not our design) was a lack of descriptor for waiting threads. Threads may be waiting for other reasons than 'set to wait for time t' and could be awoken.

 
3
	

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	In struct thread added: thread* donated_priority
Used to track current donated priority and where it came from. NULL if no donated priority.

	In struct semaphore added: list<thread*> held_by_thread
Used to track threads holding the semaphore/lock, empty if none.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

We used a series of pointers to create a linked list where we can follow where our priority came from.

How the donated priority are kept track of:
			+---------------------------+
			|                           |
Waiting for	|         Thread A          |
Lock		|       priority = 60       |
			|   donated_priority = NULL |
			|                           |<---+
			+---------------------------+    |
			                                 |
			+---------------------------+    |
			|                           |    |
Waiting for	|         Thread B          |    |
Lock    	|       priority = 40       |    |
    		|   donated_priority = -----|----+
			|                           |<---+
			+---------------------------+    | 
			                                 |
			+---------------------------+    |
			|                           |    |
Currently   |         Thread C          |    |
Holds Lock 	|       priority = 20       |    |
			|   donated_priority = -----|----+
			|                           |
			+---------------------------+
			
Since thread C looks to thread B for a higher priority and sees thread B is looking to thread A for a higher priority, thread C takes it's donated priority from thread A. Threads B and C then use the priority from A as it's used priority.

			+---------------------------+
			|                           |
Waiting for	|         Thread A          |
Lock		|       priority = 60-------|--------+
			|   donated_priority = NULL |        |
			|                           |<---+   |
			+---------------------------+    |   |
			                                 |   |
			+---------------------------+    |   |
			|                           |    |   |
Waiting for	|         Thread B          |    |   |
Lock    	|   used priority = 60 <----|----|---+
            |       priority = 40       |    |   |
    		|   donated_priority = -----|----+   |
			|                           |<---+   |
			+---------------------------+    |   |
			                                 |   |
			+---------------------------+    |   |
			|                           |    |   |
Currently   |         Thread C          |    |   |
Holds Lock 	|   used priority = 60 <----|----|---+
            |       priority = 20       |    |
			|   donated_priority = -----|----+
			|                           |
			+---------------------------+


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Inside the function sema_up, instead of waking the first waiting thread, we would wake up the thread with the highest priority (not donated_priority).

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

	Lock_acquire is called on a lock that has a lower priority thread, which we will call thread C, holding the lock. Lock_aquire() would then donate the priority of the currently running thread with a higher priority, which we will call thread A. To do this, lock_aquire will access thread C's struct and point donated_priority to thread A. Thread_yield() would be called and next_to_run() would look at thread C's donated_priority, see it is pointed to thread A, and then follow the pointer to thread A. In thread A, next_to_run() would look at donated_priority, see that it is a nullpointer, instead look at the priority of thread A and pass it back up to be used as the donated priority for thread C. Since thread C now has the highest from thread A, thread C would be chosen to run next.
	Nested donation is handled by a linked list. If thread A was donating to thread B, who was donating to thread C, then the pointer donated_priority in thread C would point to thread B, donated_priority in thread B would point to thread A, and thread A's donated_priority would be NULL. To find the priority used, we check if donated_priority is null then we use that thread's priority, if not then we continue following donated_priorty until we reach null and use the priority of the thread that is at the end of the linked list.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

	Once lock_release() is called then the current process that just released the lock will change it's donated_priority to NULL. Lock_release will then search through the threads waiting for the lock and select the thread with the highest priority (not donated_priority) and call thread_unlock on that thread.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Utilizing a lock() before we edit the priority of the thread allows us to allow only one to edit the thread's priority at a time. Yes we can use a lock to avoid the race condition.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We used the linked list approach because it means that the instant a thread's priority is updated then since the threads are pointing to the other threads, then all threads donating their priority will instantly have their donated_priority updated. We preferred this over a list stored in a thread's struc that had to be manually updated, because the updating of priority was done automatically instead of mannually. This saves us code and computing time.

			  ADVANCED SCHEDULER
			    (If Attempted)
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?